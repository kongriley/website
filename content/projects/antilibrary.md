+++
title = "Antilibrary"
description = "books, articles, resources I haven't read yet"
weight = 0
template = "info-page.html"
+++

Someday, I'll get around to reading these materials...

# Papers
[2403.13799 Golovneva et al. 2024 / Reverse Training to Nurse the Reversal Curse](https://arxiv.org/abs/2403.13799)

[2403.06634 Carlini et al. 2024 / Stealing Part of a Production Language Model](https://arxiv.org/abs/2403.06634)

[2403.19647 Marks et al. 2024 / Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models](https://arxiv.org/abs/2403.19647)

[2402.03902 Cui et al. 2024 / A phase transition between positional and semantic learning in a solvable model of dot-product attention](https://arxiv.org/abs/2402.03902)

[2404.19756 Liu et al. 2024 / KAN: Kolmogorov-Arnold Networks](https://arxiv.org/abs/2404.19756)

[2401.06121 Maini et al. 2024 / TOFU: A Task of Fictitious Unlearning for LLMs](https://arxiv.org/abs/2401.06121)

[2401.14489 Anthony et al. 2024 / The Case for Co-Designing Model Architectures with Hardware](https://arxiv.org/abs/2401.14489)

[2401.17377 Liu et al. 2024 / Infini-gram: Scaling Unbounded n-gram Language Models to a Trillion Tokens](https://arxiv.org/abs/2401.17377)

[2401.15024 Ashkboos et al. 2024 / SliceGPT: Compress Large Language Models by Deleting Rows and Columns](https://arxiv.org/abs/2401.15024)

[2401.05566 Hubinger et al. 2024 / Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training](https://arxiv.org/abs/2401.05566)

[2401.12973 Aky√ºrek et al. 2024 / In-Context Language Learning: Architectures and Algorithms](https://arxiv.org/abs/2401.12973)

[2402.04362 Belrose et al. 2024 / Neural Networks Learn Statistics of Increasing Complexity](https://arxiv.org/abs/2402.04362)


[2311.00212 Otto et al. 2023 / A Unified Framework to Enforce, Discover, and Promote Symmetry in Machine Learning](https://arxiv.org/abs/2311.00212)

[2310.19736 Guo et al. 2023 / Evaluating Large Language Models: A Comprehensive Survey](https://arxiv.org/abs/2310.19736)

[2306.03341 Li et al. 2023 / Inference-Time Intervention: Eliciting Truthful Answers from a Language Model](https://arxiv.org/abs/2306.03341)

[2309.08632 Rylan Schaeffer 2023 / Pretraining on the Test Set Is All You Need](https://arxiv.org/abs/2309.08632)

[2109.13916 Hendrycks et al. 2023 / Unsolved Problems in ML Safety](https://arxiv.org/abs/2109.13916)

[2307.08621 Sun et al. 2023 / Retentive Network: A Successor to Transformer for Large Language Models](https://arxiv.org/abs/2307.08621)

[2310.12395 Scarvelis et al. 2023 / Closed-Form Diffusion Models](https://arxiv.org/abs/2310.12395)

[2309.12288 Berglund et al. 2023 / The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A"](https://arxiv.org/abs/2309.12288)

[2311.04205 Deng et al. 2023 / Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves](https://arxiv.org/abs/2311.04205)

[2301.13310 Baykal et al. 2023 / Alternating Updates for Efficient Transformers](https://arxiv.org/abs/2301.13310)

[2311.00871 Yadlowsky et al. 2023 / Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models](https://arxiv.org/abs/2311.00871)

[2311.01906 Bobby He and Thomas Hofmann 2023 / Simplifying Transformer Blocks](https://arxiv.org/abs/2311.01906)

[2311.05232 Huang et al. 2023 / A Survey on Hallucination in Large Language Models: Principles, Taxonomy, Challenges, and Open Questions](https://arxiv.org/abs/2311.05232)

[2312.10868 McIntosh et al. 2023 / From Google Gemini to OpenAI Q* (Q-Star): A Survey of Reshaping the Generative Artificial Intelligence (AI) Research Landscape](https://arxiv.org/abs/2312.10868)

[2310.15421 Kim et al. 2023 / FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions](https://arxiv.org/abs/2310.15421)

[2307.09476 Halawi et al. 2023 / Overthinking the Truth: Understanding how Language Models Process False Demonstrations](https://arxiv.org/abs/2307.09476)

[2305.10722 He et al. 2023 / Discffusion: Discriminative Diffusion Models as Few-shot Vision and Language Learners](https://arxiv.org/abs/2305.10722)

[2305.13048 Peng et al. 2023 / RWKV: Reinventing RNNs for the Transformer Era](https://arxiv.org/abs/2305.13048)

[2310.16789 Shi et al. 2023 / Detecting Pretraining Data from Large Language Models](https://arxiv.org/abs/2310.16789)

[2302.12239 Galke et al. 2023 / What Makes a Language Easy to Deep-Learn?](https://arxiv.org/abs/2302.12239)

[2306.04719 Geirhos et al. 2023 / Don't trust your eyes: on the (un)reliability of feature visualizations](https://arxiv.org/abs/2306.04719)

[2310.02446 Yong et al. 2023 / Low-Resource Languages Jailbreak GPT-4](https://arxiv.org/abs/2310.02446)

[2210.03057 Shi et al. 2022 / Language Models are Multilingual Chain-of-Thought Reasoners](https://arxiv.org/abs/2210.03057)

[2212.03827 Burns et al. 2022 / Discovering Latent Knowledge in Language Models Without Supervision](https://arxiv.org/abs/2212.03827)

[2201.11903 Wei et al. 2022 / Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903)

[2106.06981 Weiss et al. 2021 / Thinking Like Transformers](https://arxiv.org/abs/2106.06981)

[2006.07733 Grill et al. 2020 / Bootstrap your own latent: A new approach to self-supervised Learning](https://arxiv.org/abs/2006.07733)

[2005.11401 Lewis et al. 2020 / Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)

[1807.11205 Jia et al. 2018 / Highly Scalable Deep Learning Training System with Mixed-Precision: Training ImageNet in Four Minutes](https://arxiv.org/abs/1807.11205)

[1802.09568 Gupta et al. 2018 / Shampoo: Preconditioned Stochastic Tensor Optimization](https://arxiv.org/abs/1802.09568)

[1706.02677 Goyal et al. 2017 / Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour](https://arxiv.org/abs/1706.02677)

[1612.00796 Kirkpatrick et al. 2016 / Overcoming catastrophic forgetting in neural networks](https://arxiv.org/abs/1612.00796)

[1312.6211 Goodfellow et al. 2013 / An Empirical Investigation of Catastrophic Forgetting in Gradient-Based Neural Networks](https://arxiv.org/abs/1312.6211)

<!--
# big list
- (any untagged papers in this vault)
- https://www.lesswrong.com/posts/CkFBMG6A9ytkiXBDM/sparse-autoencoders-future-work
- https://www.lesswrong.com/posts/iGuwZTHWb6DFY3sKB/fact-finding-attempting-to-reverse-engineer-factual-recall
- http://programmersstone.com/Day1.html
- https://mml-book.github.io/book/mml-book.pdf
- [[CAGE Probing Causal Relationships in Deep Generative Models]]
- [[Eight Things to Know about Large Language Models]]
- https://arxiv.org/abs/2312.10997v1?utm_source=substack&utm_medium=email

- arena
	- https://course.fast.ai/
	- https://distill.pub/2017/momentum/
	- https://explained.ai/matrix-calculus/
	- https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf
	- https://rockt.github.io/2018/04/30/einsum
	- https://www.lesswrong.com/posts/no5jDTut5Byjqb4j5/six-and-a-half-intuitions-for-kl-divergence
	- https://theaisummer.com/skip-connections/#:~:text=residual%20skip%20connections.-,ResNet%3A%20skip%20connections%C2%A0via%C2%A0addition,-The%20core%20idea
	- https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html
	- https://gitimmersion.com/lab_10.html
	- https://code.visualstudio.com/docs/python/jupyter-support-py
- https://atlasfellowship.notion.site/Atlas-Library-af2b3a58670c4b4d8c49856c10e8594f
	- https://www.goodreads.com/book/show/25744928-deep-work
	- https://algorithmstoliveby.com/
	- https://mindingourway.com/
	- https://mistral.ai/news/announcing-mistral-7b/
- https://blog.eleuther.ai/transformer-math/

## 2024/06/09
https://fullstackdeeplearning.com/llm-bootcamp/
https://os.phil-opp.com/
https://notes.ekzhang.com/events/hsrg
https://notes.ekzhang.com/events/nysrg
https://github.com/fc2869/lo-fit

## 2024/5/21
https://github.com/microsoft/unilm/blob/master/bitnet/The-Era-of-1-bit-LLMs__Training_Tips_Code_FAQ.pdf
https://www.vincentsitzmann.com/
file:///C:/Users/kongr/Downloads/2022.cmcl-1.10.pdf
https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf
quant
- https://github.com/northwesternfintech/2025QuantInternships
- https://www.math.lsu.edu/~smolinsk/Quant_Interview_Prep.pdf

## 2024/5/18
https://johnowhitaker.github.io/tglcourse/
https://onedo.today/
https://transformer-circuits.pub/2024/april-update/index.html

## 2024/5/8
https://eureka-research.github.io/

## 2024/1/26 dump
- cold diffusion https://arxiv.org/pdf/2208.09392.pdf
- https://distill.pub/2020/growing-ca/
- [[DPO]]
- readout guidance https://readout-guidance.github.io/
- https://transformer-circuits.pub/2024/jan-update/index.html
- https://www.apolloresearch.ai/blog/a-starter-guide-for-evals
- https://blog.eleuther.ai/diff-in-means/https://www.lesswrong.com/posts/kuQfnotjkQA4Kkfou/inference-time-intervention-eliciting-truthful-answers-from

## 2024/1/31 dump
https://jsseely.com/mamba/
https://distill.pub/2020/selforg/mnist/
https://transformer-circuits.pub/
https://www.lesswrong.com/posts/f9EgfLSurAiqRJySD/open-source-sparse-autoencoders-for-all-residual-stream#What_are_Sparse_AutoEncoders_and_why_should_we_care_about_them_
https://blog.eleuther.ai/diff-in-means/
https://www.lesswrong.com/posts/kcKrE9mzEHrdqtDpE/the-case-for-ensuring-that-powerful-ais-are-controlled
https://www.alignmentforum.org/posts/iy2o4nQj9DnQD7Yhj/discussion-with-nate-soares-on-a-key-alignment-difficulty
https://www.lesswrong.com/posts/uMQ3cqWDPHhjtiesc/agi-ruin-a-list-of-lethalities
https://unstableontology.com/2023/12/31/a-case-for-ai-alignment-being-difficult/
https://www.lesswrong.com/posts/LNA8mubrByG7SFacm/against-almost-every-theory-of-impact-of-interpretability-1
https://www.lesswrong.com/posts/K2D45BNxnZjdpSX2j/#Overall_summary__takeaways_and_next_steps
https://www.lesswrong.com/posts/2roZtSr5TGmLjXMnT/toward-a-mathematical-framework-for-computation-in#
https://www.lesswrong.com/posts/aWPucqvJ4RWKKwKjH/4-min-read-an-intuitive-explanation-of-the-ai-influence#


## 2024/2/5 dump
https://www.jasonwei.net/blog/practicing-ai-research

# bigger stuff

* Thinking, Fast and Slow
* GEB
* Starting Strength
* Grit (Angela Duckworth)
* Peak (Anders Ericsson)
* Categories for the Working Mathematician

programming languages
- haskell https://www.haskell.org/get-started/
- rust 

https://missing.csail.mit.edu/

ux/ui
- https://docs.google.com/document/d/1yJ1YCo0eS3dt2jWQRAraXfe79BRaSeS1rUKORFWpwX4/edit
	- https://start.uxdesign.cc/industry-overview/

https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf
https://pages.cs.wisc.edu/~remzi/OSTEP/

https://neetcode.io/roadmap

# already read

lesswrong
- https://www.lesswrong.com/posts/ii4xtogen7AyYmN6B/learning-by-writing#
	- informative on how to form opinions using writing
- https://www.lesswrong.com/posts/nvmfqdytxyEpRJC3F/is-being-sexy-for-your-homies
	- girl... wtf
- https://www.lesswrong.com/posts/B3z8PMqor3rivzgAv/deep-dives-my-advice-for-pursuing-work-in-research
	- good work!
	- how to take the first step in discovering what you can signal for

- https://www.neelnanda.io/mechanistic-interpretability/getting-started
- https://zhangir-azerbayev.github.io/posts/2022-04-28-gowers.html
- https://en.wikipedia.org/wiki/Wikipedia:Be_bold

https://www.technologyreview.com/2024/03/04/1089403/large-language-models-amazing-but-nobody-knows-why/

https://learnhowtolearn.org/how-i-cured-procrastination/

## literature
- ernest hemingway
	- the old man and the sea

-->